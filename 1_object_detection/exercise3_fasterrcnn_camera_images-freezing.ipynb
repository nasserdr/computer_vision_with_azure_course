{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objectives\r\n",
        "In this Notebook, we will apply image augmentation to the dataset from the previous exercise hopefully we can allegiate overfitting.\r\n",
        "\r\n",
        "After going through this notebook, you will be able to:\r\n",
        "- Apply image augmentation\r\n",
        "\r\n",
        "Requirments:\r\n",
        "- Data used in this notebook are downloaded in the previous notebook.\r\n",
        "- Install are mentionned in the exercise 1 as well."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\r\n",
        "\r\n",
        "This notebook should use torchvision and torch versions that are compatible with each other. For more information, visit [this link](https://pypi.org/project/torchvision/).\r\n",
        "\r\n",
        "For demonstration purposes, we use the torch version 1.12.1 and the torchvision 0.13.1. However, users may install and use other versions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Env: azureml_py38_PT_TF\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "print('The version of PyTorch is {}'.format(torch.__version__))\r\n",
        "print('The version of Torchvision is {}'.format(torchvision.__version__))\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('There are {} cuda devices'.format(torch.cuda.device_count()))\r\n",
        "print('Used device is {}'.format(device))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877375171
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common imports\r\n",
        "The below improts are encountered in most of the computer vision projects. Though, you may need to adapt them according to your needs."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\r\n",
        "import json, os, random\r\n",
        "random.seed(1985)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "from torch.utils.data import random_split\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision.ops import nms\r\n",
        "\r\n",
        "\r\n",
        "from torch_snippets import *\r\n",
        "from project_utils import *\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670877376130
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuring some pathes to make it easier to call images and annotations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The pathes on AzureML are a bit strange\r\n",
        "full_path = os.getcwd().split('/')\r\n",
        "#This will adapt the user name to your specific machine\r\n",
        "home = os.path.join(os.path.expanduser('~'), 'cloudfiles/code/Users/' + full_path[11])\r\n",
        "print('Home Directory - Full Path: {}\\n'.format(home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "notebook_home = os.path.join(home, 'computer_vision_with_azure_course/1_object_detection')\r\n",
        "print('Notebbok Directory: {}\\n'.format(notebook_home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "images_home = os.path.join(home, 'data/rumex/images')\r\n",
        "print('Images Directory: {}\\n'.format(images_home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "annotations_home = os.path.join(home, 'computer_vision_with_azure_course/1_object_detection/annotations')\r\n",
        "print('Annotations Directory: {}\\n'.format(annotations_home))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877376402
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading annotations\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the function\r\n",
        "annotations_link = os.path.join(annotations_home, 'annotations.csv')\r\n",
        "df = load_clean_annotations(annotations_link, images_home)\r\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877376573
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image augmentation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transforms as T\r\n",
        "\r\n",
        "def get_transform(train):\r\n",
        "    transforms = []\r\n",
        "    #transforms.append(T.PILToTensor())\r\n",
        "    #transforms.append(T.ConvertImageDtype(torch.float))\r\n",
        "    if train:\r\n",
        "        transforms.append(T.RandomHorizontalFlip(0.7))\r\n",
        "        transforms.append(T.RandomIoUCrop())\r\n",
        "        transforms.append(T.RandomIoUCrop())\r\n",
        "        transforms.append(T.RandomZoomOut())\r\n",
        "        transforms.append(T.RandomPhotometricDistort())\r\n",
        "        #transforms.append(T.ScaleJitter())\r\n",
        "        #transforms.append(T.RandomShortestSize())\r\n",
        "    return T.Compose(transforms)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877380373
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "annotations_link = os.path.join(annotations_home, 'annotations.csv')\r\n",
        "annotations_df = load_clean_annotations(annotations_link, images_home)\r\n",
        "\r\n",
        "\r\n",
        "trn_ids, val_ids = train_test_split(df['External ID'].unique(), test_size=0.3, random_state=99)\r\n",
        "trn_df, val_df = df[df['External ID'].isin(trn_ids)], df[df['External ID'].isin(val_ids)]\r\n",
        "\r\n",
        "trn_df.reset_index(inplace = True, drop=True)\r\n",
        "val_df.reset_index(inplace = True, drop=True)\r\n",
        "\r\n",
        "print(len(trn_df))\r\n",
        "print(len(val_df))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877380558
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = RumexDataSetLabelBox(images_home, trn_df, transforms=get_transform('train'))\r\n",
        "val_data = RumexDataSetLabelBox(images_home, val_df)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877380715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\r\n",
        "        train_data,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=False,\r\n",
        "        collate_fn=collate_fn\r\n",
        "    )\r\n",
        "\r\n",
        "val_loader = DataLoader(\r\n",
        "        val_data,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=False,\r\n",
        "        collate_fn=collate_fn\r\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877380852
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freezing layers"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Make sure the device is a cuda device: \\n Found device: {}'.format(device))\r\n",
        "model = get_model().to(device)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877381014
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the names of parameters  requiring grad (not-freezed)\r\n",
        "for name, parameter in model.named_parameters():\r\n",
        "    if parameter.requires_grad:\r\n",
        "        print(name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877382474
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing the whole backbone  (convolutional layers and FPN): We don't want to do this\r\n",
        "'''\r\n",
        "layer_counter = 0\r\n",
        "for (name, module) in model.named_children():\r\n",
        "    if name == 'backbone':\r\n",
        "        for layer in module.children():\r\n",
        "            for param in layer.parameters():\r\n",
        "                param.requires_grad = False\r\n",
        "            \r\n",
        "            print('Layer \"{}\" in module \"{}\" was frozen!'.format(layer_counter, name))\r\n",
        "            layer_counter+=1\r\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877382623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Freezing the backbone convolutional layers ONLY\r\n",
        "layer_counter = 0\r\n",
        "for (name, module) in model.named_children():\r\n",
        "    if name == 'backbone':\r\n",
        "        for body_name, child in module.named_children():\r\n",
        "            if body_name == 'body':\r\n",
        "                for param in child.parameters():\r\n",
        "                    param.requires_grad = False\r\n",
        "                \r\n",
        "                print('Layer \"{}\" in module \"{}\" was frozen!'.format(layer_counter, name))\r\n",
        "                layer_counter+=1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877382776
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the names of parameters requiring grad (not-freezed)\r\n",
        "for name, parameter in model.named_parameters():\r\n",
        "    if parameter.requires_grad:\r\n",
        "        print(name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877383369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#help(Report)\r\n",
        "import wandb\r\n",
        "wandb.init(project='faster_rcnn_camera')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877384253
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_freezed_parameters = filter(lambda p: p.requires_grad, model.parameters())\r\n",
        "optimizer = torch.optim.SGD(non_freezed_parameters, lr=0.005, momentum=0.9, weight_decay=0.0005)\r\n",
        "n_epochs = 20\r\n",
        "log = Report(n_epochs) #From pytorch_snipets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877398526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_batch(inputs, model, optimizer):\r\n",
        "    model.train()\r\n",
        "    input, targets = inputs\r\n",
        "    input = list(image.to(device) for image in input)\r\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\r\n",
        "    optimizer.zero_grad()\r\n",
        "    losses = model(input, targets)\r\n",
        "    loss = sum(loss for loss in losses.values())\r\n",
        "    #loss = Variable(loss, requires_grad = True) #Used in case grad is activated outside the loop\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    return loss, losses\r\n",
        "\r\n",
        "@torch.no_grad() # this will disable gradient computation in the function below\r\n",
        "def validate_batch(inputs, model):\r\n",
        "    model.train() # to obtain the losses, model needs to be in train mode only. # #Note that here we are not defining the model's forward method \r\n",
        "#and hence need to work per the way the model class is defined\r\n",
        "    input, targets = inputs\r\n",
        "    input = list(image.to(device) for image in input)\r\n",
        "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\r\n",
        "    optimizer.zero_grad()\r\n",
        "    losses = model(input, targets)\r\n",
        "    loss = sum(loss for loss in losses.values())\r\n",
        "    return loss, losses\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670877400204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\r\n",
        "    _n = len(train_loader)\r\n",
        "    for ix, inputs in enumerate(train_loader):\r\n",
        "        loss, losses = train_batch(inputs, model, optimizer)\r\n",
        "        loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\r\n",
        "            [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\r\n",
        "        pos = (epoch + (ix+1)/_n)\r\n",
        "        \r\n",
        "        log.record(pos, trn_loss=loss.item(), trn_loc_loss=loc_loss.item(), \r\n",
        "                trn_regr_loss=regr_loss.item(), trn_objectness_loss=loss_objectness.item(),\r\n",
        "                trn_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\r\n",
        "        \r\n",
        "\r\n",
        "    _n = len(val_loader)\r\n",
        "    for ix,inputs in enumerate(val_loader):\r\n",
        "        loss, losses = validate_batch(inputs, model)\r\n",
        "        loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\r\n",
        "        [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\r\n",
        "        pos = (epoch + (ix+1)/_n)\r\n",
        "        \r\n",
        "        log.record(pos, val_loss=loss.item(), val_loc_loss=loc_loss.item(), \r\n",
        "                val_regr_loss=regr_loss.item(), val_objectness_loss=loss_objectness.item(),\r\n",
        "                val_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\r\n",
        "        \r\n",
        "    if (epoch+1)%(n_epochs//5)==0:\r\n",
        "        #call(\"nvidia-smi\")\r\n",
        "        log.report_avgs(epoch+1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670881461263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670881461454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\r\n",
        "for ix, (images, targets) in enumerate(val_loader):\r\n",
        "    if ix==1: break\r\n",
        "    images = [im for im in images]\r\n",
        "    outputs = model(images)\r\n",
        "    \r\n",
        "    for ix, output in enumerate(outputs):\r\n",
        "        bbs, confs, labels = decode_output(output)\r\n",
        "        #print(bbs)\r\n",
        "        #print(confs)\r\n",
        "        #print(labels)\r\n",
        "        #info = [f'{l}@{c:.2f}' for l,c in zip(labels, confs)]\r\n",
        "        show(images[ix].cpu().permute(1,2,0), bbs=bbs, texts=labels, sz=5) #Show from pytorch snippets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670881466789
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"models/model_freezed.pth\")\r\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670881468364
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}