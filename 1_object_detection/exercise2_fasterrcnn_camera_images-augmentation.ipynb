{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objectives\r\n",
        "In this Notebook, we will apply image augmentation to the dataset from the previous exercise hopefully we can allegiate overfitting.\r\n",
        "\r\n",
        "After going through this notebook, you will be able to:\r\n",
        "- Apply image augmentation\r\n",
        "\r\n",
        "Requirments:\r\n",
        "- Data used in this notebook are downloaded in the previous notebook.\r\n",
        "- Install are mentionned in the exercise 1 as well."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\r\n",
        "\r\n",
        "This notebook should use torchvision and torch versions that are compatible with each other. For more information, visit [this link](https://pypi.org/project/torchvision/).\r\n",
        "\r\n",
        "For demonstration purposes, we use the torch version 1.12.1 and the torchvision 0.13.1. However, users may install and use other versions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Env: azureml_py38_PT_TF\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "print('The version of PyTorch is {}'.format(torch.__version__))\r\n",
        "print('The version of Torchvision is {}'.format(torchvision.__version__))\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('There are {} cuda devices'.format(torch.cuda.device_count()))\r\n",
        "print('Used device is {}'.format(device))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The version of PyTorch is 1.12.1\nThe version of Torchvision is 0.13.1\nThere are 1 cuda devices\nUsed device is cuda\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668165318
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common imports\r\n",
        "The below improts are encountered in most of the computer vision projects. Though, you may need to adapt them according to your needs."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\r\n",
        "import json, os, random\r\n",
        "random.seed(1985)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "\r\n",
        "from torch.utils.data import random_split\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\r\n",
        "from torch.autograd import Variable\r\n",
        "from torchvision.ops import nms\r\n",
        "\r\n",
        "\r\n",
        "from torch_snippets import *\r\n",
        "from project_utils import *\r\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670668166462
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuring some pathes to make it easier to call images and annotations"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The pathes on AzureML are a bit strange\r\n",
        "full_path = os.getcwd().split('/')\r\n",
        "#This will adapt the user name to your specific machine\r\n",
        "home = os.path.join(os.path.expanduser('~'), 'cloudfiles/code/Users/' + full_path[11])\r\n",
        "print('Home Directory - Full Path: {}\\n'.format(home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "notebook_home = os.path.join(home, 'computer_vision_with_azure_course/1_object_detection')\r\n",
        "print('Notebbok Directory: {}\\n'.format(notebook_home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "images_home = os.path.join(home, 'data/rumex/images')\r\n",
        "print('Images Directory: {}\\n'.format(images_home))\r\n",
        "\r\n",
        "#The Notebook directory\r\n",
        "annotations_home = os.path.join(home, 'computer_vision_with_azure_course/1_object_detection/annotations')\r\n",
        "print('Annotations Directory: {}\\n'.format(annotations_home))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Home Directory - Full Path: \u001b[35m/home/azureuser/cloudfiles/code/Users/\u001b[0m\u001b[95mroland.nasser.agroscope\u001b[0m\n\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Home Directory - Full Path: <span style=\"color: #800080; text-decoration-color: #800080\">/home/azureuser/cloudfiles/code/Users/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">roland.nasser.agroscope</span>\n\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Notebbok Directory: \n\u001b[35m/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/computer_vision_with_azure_course/\u001b[0m\u001b[95m1_object_detection\u001b[0m\n\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Notebbok Directory: \n<span style=\"color: #800080; text-decoration-color: #800080\">/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/computer_vision_with_azure_course/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">1_object_detection</span>\n\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Images Directory: \u001b[35m/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/data/rumex/\u001b[0m\u001b[95mimages\u001b[0m\n\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Images Directory: <span style=\"color: #800080; text-decoration-color: #800080\">/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/data/rumex/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">images</span>\n\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Annotations Directory: \n\u001b[35m/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/computer_vision_with_azure_course/1_object_detection/\u001b[0m\n\u001b[95mannotations\u001b[0m\n\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Annotations Directory: \n<span style=\"color: #800080; text-decoration-color: #800080\">/home/azureuser/cloudfiles/code/Users/roland.nasser.agroscope/computer_vision_with_azure_course/1_object_detection/</span>\n<span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">annotations</span>\n\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668167634
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading annotations\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the function\r\n",
        "annotations_link = os.path.join(annotations_home, 'annotations.csv')\r\n",
        "df = load_clean_annotations(annotations_link, images_home)\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "                                               Label   External ID\n0  {\"Wurzelpunkt\":[{\"geometry\":{\"x\":821,\"y\":424}}...  img_2001.png\n1  {\"Wurzelpunkt\":[{\"geometry\":{\"x\":651,\"y\":493}}...  img_2008.png\n2  {\"Wurzelpunkt\":[{\"geometry\":{\"x\":545,\"y\":699}}...  img_2009.png\n3  {\"Wurzelpunkt\":[{\"geometry\":{\"x\":740,\"y\":527}}...  img_2010.png\n4  {\"Wurzelpunkt\":[{\"geometry\":{\"x\":697,\"y\":666}}...  img_2011.png",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>External ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{\"Wurzelpunkt\":[{\"geometry\":{\"x\":821,\"y\":424}}...</td>\n      <td>img_2001.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{\"Wurzelpunkt\":[{\"geometry\":{\"x\":651,\"y\":493}}...</td>\n      <td>img_2008.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{\"Wurzelpunkt\":[{\"geometry\":{\"x\":545,\"y\":699}}...</td>\n      <td>img_2009.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{\"Wurzelpunkt\":[{\"geometry\":{\"x\":740,\"y\":527}}...</td>\n      <td>img_2010.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{\"Wurzelpunkt\":[{\"geometry\":{\"x\":697,\"y\":666}}...</td>\n      <td>img_2011.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668167991
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image augmentation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transforms as T\r\n",
        "\r\n",
        "def get_transform(train):\r\n",
        "    transforms = []\r\n",
        "    #transforms.append(T.PILToTensor())\r\n",
        "    #transforms.append(T.ConvertImageDtype(torch.float))\r\n",
        "    #if train:\r\n",
        "        #transforms.append(T.RandomHorizontalFlip(0.5))\r\n",
        "        #transforms.append(T.RandomIoUCrop())\r\n",
        "        #transforms.append(T.RandomPhotometricDistort())\r\n",
        "    return T.Compose(transforms)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "annotations_link = os.path.join(annotations_home, 'annotations.csv')\r\n",
        "annotations_df = load_clean_annotations(annotations_link, images_home)\r\n",
        "\r\n",
        "\r\n",
        "trn_ids, val_ids = train_test_split(df['External ID'].unique(), test_size=0.3, random_state=99)\r\n",
        "trn_df, val_df = df[df['External ID'].isin(trn_ids)], df[df['External ID'].isin(val_ids)]\r\n",
        "\r\n",
        "trn_df.reset_index(inplace = True, drop=True)\r\n",
        "val_df.reset_index(inplace = True, drop=True)\r\n",
        "\r\n",
        "print(len(trn_df))\r\n",
        "print(len(val_df))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = RumexDataSetLabelBox(images_home, trn_df, transforms=get_transform('train'))\r\n",
        "val_data = RumexDataSetLabelBox(images_home, val_df)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\r\n",
        "        train_data,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=False,\r\n",
        "        collate_fn=collate_fn\r\n",
        "    )\r\n",
        "\r\n",
        "val_loader = DataLoader(\r\n",
        "        val_data,\r\n",
        "        batch_size=8,\r\n",
        "        shuffle=False,\r\n",
        "        collate_fn=collate_fn\r\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065599
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Make sure the device is a cuda device: \\n Found device: {}'.format(device))\r\n",
        "model = get_model().to(device)\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.05)\r\n",
        "n_epochs = 20\r\n",
        "log = Report(n_epochs) #From pytorch_snipets\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065707
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\r\n",
        "    for epoch in range(n_epochs):\r\n",
        "        _n = len(train_loader)\r\n",
        "        for ix, inputs in enumerate(train_loader):\r\n",
        "            loss, losses = train_batch(inputs, model, optimizer)\r\n",
        "            loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\r\n",
        "                [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\r\n",
        "            pos = (epoch + (ix+1)/_n)\r\n",
        "            \r\n",
        "            log.record(pos, trn_loss=loss.item(), trn_loc_loss=loc_loss.item(), \r\n",
        "                    trn_regr_loss=regr_loss.item(), trn_objectness_loss=loss_objectness.item(),\r\n",
        "                    trn_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\r\n",
        "            \r\n",
        "\r\n",
        "        _n = len(val_loader)\r\n",
        "        for ix,inputs in enumerate(val_loader):\r\n",
        "            loss, losses = validate_batch(inputs, model, optimizer)\r\n",
        "            loc_loss, regr_loss, loss_objectness, loss_rpn_box_reg = \\\r\n",
        "            [losses[k] for k in ['loss_classifier','loss_box_reg','loss_objectness','loss_rpn_box_reg']]\r\n",
        "            pos = (epoch + (ix+1)/_n)\r\n",
        "            \r\n",
        "            log.record(pos, val_loss=loss.item(), val_loc_loss=loc_loss.item(), \r\n",
        "                    val_regr_loss=regr_loss.item(), val_objectness_loss=loss_objectness.item(),\r\n",
        "                    val_rpn_box_reg_loss=loss_rpn_box_reg.item(), end='\\r')\r\n",
        "            \r\n",
        "        if (epoch+1)%(n_epochs//5)==0:\r\n",
        "            #call(\"nvidia-smi\")\r\n",
        "            log.report_avgs(epoch+1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670668065770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670667937694
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\r\n",
        "for ix, (images, targets) in enumerate(test_loader):\r\n",
        "    if ix==1: break\r\n",
        "    images = [im for im in images]\r\n",
        "    outputs = model(images)\r\n",
        "    \r\n",
        "    for ix, output in enumerate(outputs):\r\n",
        "        bbs, confs, labels = decode_output(output)\r\n",
        "        #print(bbs)\r\n",
        "        #print(confs)\r\n",
        "        #print(labels)\r\n",
        "        #info = [f'{l}@{c:.2f}' for l,c in zip(labels, confs)]\r\n",
        "        show(images[ix].cpu().permute(1,2,0), bbs=bbs, texts=labels, sz=5) #Show from pytorch snippets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670667937722
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"models/model_augmentation.pth\")\r\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670667937749
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}